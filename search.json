[{"path":"https://melodyyhuang.github.io/senseweight/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 senseweight authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":[]},{"path":"https://melodyyhuang.github.io/senseweight/articles/external-validity.html","id":"robustness-value","dir":"Articles","previous_headings":"Sensitivity Summary Measures","what":"Robustness value","title":"Sensitivity analysis for external validity","text":"can generate sensitivity summary measures using summarize_sensitivity function: summarize_sensitivity function defaults evaluating robustness value q=1, indicating robustness value, relative bias equal point estimate. Researchers can specify different values q function. generalization setting, researchers can modify sigma2 bound posit values plausible bound (given substantive justification). specification, sigma2 automatically calculated bound var(Y(1)) + var(Y(0)).","code":"summarize_sensitivity(   weights = weights,    Y = df_site$Y,    Z = df_site$T,    sigma2 = vartau,    estimand = \"PATE\" ) #>   Unweighted Unweighted_SE Estimate     SE   RV sigma_tau_bound cor_w #> Z    1107.35        982.65  1356.66 1417.3 0.36          2897.9  0.07 RV = robustness_value(estimate = ipw, b_star = 0, sigma2 = vartau, weights = weights) print(RV) #> [1] 0.4113622"},{"path":"https://melodyyhuang.github.io/senseweight/articles/external-validity.html","id":"benchmarking","dir":"Articles","previous_headings":"Sensitivity Summary Measures","what":"Benchmarking","title":"Sensitivity analysis for external validity","text":"","code":"# Select weighting variables: weighting_vars = names(df_all)[which(!names(df_all) %in% c(\"site\", \"S\", \"Y\", \"T\"))]  # Run bechmarking: df_benchmark <- run_benchmarking(   weighting_vars = weighting_vars,   data = df_all[, -1],   treatment = \"T\", outcome = \"Y\", selection = \"S\",   estimate = ipw,   RV = RV, sigma2 = vartau,   estimand = \"PATE\" )   print(df_benchmark) #>   variable R2_benchmark rho_benchmark    bias    MRCS k_sigma_min k_rho_min #> 1 prevearn         0.04         -0.22 -115.00  -11.80        9.99     -2.92 #> 2      age         0.06         -0.09  -55.45  -24.47        6.91     -7.37 #> 3  married         0.11          0.00   -2.52 -539.33        3.82   -224.19 #> 4   hrwage         0.05          0.02   13.51  100.40        8.32     27.40 #> 5    black         0.20         -0.03  -33.11  -40.97        2.03    -24.72 #> 6 hispanic         0.14         -0.06  -62.63  -21.66        3.01    -10.30 #> 7  hsorged         0.12          0.10   95.06   14.27        3.51      6.22 #> 8 yrs_educ         0.00         -0.07   -5.23 -259.49      408.90     -9.85"},{"path":"https://melodyyhuang.github.io/senseweight/articles/external-validity.html","id":"bias-contour-plot","dir":"Articles","previous_headings":"Sensitivity Summary Measures","what":"Bias Contour Plot","title":"Sensitivity analysis for external validity","text":"","code":"contour_plot(   var(weights), vartau, ipw, df_benchmark,   benchmark = TRUE, shade = TRUE,   shade_var = c(\"age\", \"prevearn\"),   label_size = 4 )"},{"path":"https://melodyyhuang.github.io/senseweight/articles/survey.html","id":"setting-up-survey-objects","dir":"Articles","previous_headings":"","what":"Setting up survey objects","title":"Sensitivity analysis for survey weights","text":"senseweight package builds top survey package conduct sensitivity analysis. start, set different survey objects analysis. created vector population targets using subset 2020 CES. locally stored vector pop_targets: use raking weighting method choice. unweighted survey estimate 0.54. contrast, weighted survey estimate 0.47.","code":"poll_srs <- svydesign(ids = ~ 1, data = poll.data) pop_targets = c(1, 0.212, 0.264, 0.236, 0.310,                  0.114, 0.360, 0.528, 0.114,                  0.021, 0.034, 0.805,                  0.266, 0.075, 0.312, 0.349) #Match covariate names in polling data  names(pop_targets) = model.matrix(~.-Y, data = poll.data) |> colnames() print(pop_targets) #>             (Intercept)       age_buckets36to50       age_buckets51to64  #>                   1.000                   0.212                   0.264  #>       age_bucketsOver65 educHigh School or Less           educPost-grad  #>                   0.236                   0.310                   0.114  #>        educSome college             genderWomen               raceBlack  #>                   0.360                   0.528                   0.114  #>            raceHispanic               raceOther               raceWhite  #>                   0.021                   0.034                   0.805  #>          pidIndependent                pidOther           pidRepublican  #>                   0.266                   0.075                   0.312  #>            bornagainYes  #>                   0.349 #Set up raking formula: formula_rake <- ~ age_buckets + educ + gender + race + pid + bornagain  #PERFORM RAKING: model_rake <- calibrate(   design = poll_srs,   formula = formula_rake,   population = pop_targets,   calfun = \"raking\",   force = TRUE )   rake_results <- svydesign( ~ 1, data = poll.data, weights = stats::weights(model_rake)) #Estimate from raking results: weights = stats::weights(rake_results) * nrow(model_rake)  unweighted_estimate = svymean(~ Y, poll_srs, na.rm = TRUE) weighted_estimate = svymean(~ Y, model_rake, na.rm = TRUE) print(unweighted_estimate) #>   mean     SE #> Y 0.54 0.0158 print(weighted_estimate) #>      mean     SE #> Y 0.46843 0.0168"},{"path":"https://melodyyhuang.github.io/senseweight/articles/survey.html","id":"summarizing-sensitivity","dir":"Articles","previous_headings":"","what":"Summarizing sensitivity","title":"Sensitivity analysis for survey weights","text":"survey objects, can now generate sensitivity summaries. senseweight package provides functions researchers generate (1) robustness values; (2) benchmarking results; (3) bias contour plots. walk .","code":""},{"path":"https://melodyyhuang.github.io/senseweight/articles/survey.html","id":"robustness-value","dir":"Articles","previous_headings":"Summarizing sensitivity","what":"Robustness Value","title":"Sensitivity analysis for survey weights","text":"robustness value single numeric summary capturing strong confounder change research conclusion. general, refer confounder results enough bias alter research conclusion killer confounder. threshold bias results killer confounder depends substantive context. example, trying measure support. Thus, bias large enough move estimate 0.47 beyond 0.5, imply proportion individuals support policy change minority majority. summarize_sensitivity function produce table outputs unweighted estimate, weighted estimate, robustness value corresponding threshold value b*b^*. specification threshold value given b_star argument summarize_sensitivity function. obtain robustness value 0.05. implies error omitting confounder able explain 5% variation oracle weights 5% variation outcome, sufficient push survey estimate 50% threshold. can also choose directly estimate robustness value using robustness_value function:","code":"summarize_sensitivity(estimand = 'Survey',                       Y = poll.data$Y,                       weights = weights,                       svy_srs = unweighted_estimate,                        svy_wt = weighted_estimate,                       b_star = 0.5) #>   Unweighted Unweighted_SE  Estimate        SE         RV #> 1       0.54     0.0157686 0.4684269 0.0167966 0.04977723 robustness_value(estimate = as.numeric(weighted_estimate[1]),                  b_star = 0.5,                  sigma2 = var(poll.data$Y),                   weights = weights) #> [1] 0.04977723"},{"path":"https://melodyyhuang.github.io/senseweight/articles/survey.html","id":"benchmarking","dir":"Articles","previous_headings":"Summarizing sensitivity","what":"Benchmarking","title":"Sensitivity analysis for survey weights","text":"help reason plausibility potential confounders, can also perform benchmarking. Benchmarking allows researchers estimate magnitude sensitivity parameters correspond omitted confounder equivalent confounding strength observed covariate. benchmark single covariate, can use benchmark_survey function: interpret benchmarking result , see omitting confounder equivalent confounding strength omitting education, controlling covariates, result R2R^2 parameter 0.32, correlation value 0.06. results bias 0.03. Alternatively, can choose benchmark covariates calling run_benchmarking. specify survey setting, set estimand = \"Survey\" function: function automatically return benchmarking results, well measure called minimum relative confounding strength (MRCS), calculates much stronger (weaker) omitted confounder must , relative observed covariate, order killer confounder. MRCS greater 1, implies omitted confounder stronger observed covariate result killer confounder. contrast, MRCS less 1, implies omitted confounder can weaker observed covariate result killer confounder.","code":"benchmark_survey('educ',                   formula = formula_rake,                  weights = weights,                  population_targets = pop_targets,                  sample_svy = poll_srs,                  Y = poll.data$Y) #>   variable R2_benchmark rho_benchmark       bias #> 1     educ    0.3193473    0.06009261 0.02545009 covariates = c(\"age_buckets\", \"educ\", \"gender\", \"race\",                \"educ\", \"pid\", \"bornagain\")  benchmark_results = run_benchmarking(estimate = as.numeric(weighted_estimate[1]),                  RV = 0.05,                  formula = formula_rake,                  weights = weights,                  Y = poll.data$Y,                  sample_svy = poll_srs,                  population_targets = pop_targets,                  estimand= \"Survey\") print(benchmark_results) #>      variable R2_benchmark rho_benchmark  bias   MRCS k_sigma_min k_rho_min #> 1 age_buckets         0.39          0.05  0.02  20.19        0.13      4.79 #> 2        educ         0.32          0.06  0.03  18.41        0.16      3.72 #> 3      gender         0.07         -0.05 -0.01 -57.15        0.74     -4.54 #> 4        race         0.06          0.03  0.01  86.03        0.79      6.58 #> 5         pid         0.04          0.04  0.01  79.50        1.16      4.98 #> 6   bornagain         0.07          0.07  0.01  39.04        0.75      3.09"},{"path":"https://melodyyhuang.github.io/senseweight/articles/survey.html","id":"bias-contour-plot","dir":"Articles","previous_headings":"Summarizing sensitivity","what":"Bias contour plot","title":"Sensitivity analysis for survey weights","text":"visualize sensitivity underlying estimates, can generate bias contour plot using following contour_plot function:  yy-axis varies degree omitted confounder imbalanced, xx-axis varies degree imbalance omitted confounder related outcome. resulting contours represent bias occurs specified {ρ,R2}\\{\\rho, R^2\\} value. shaded region denotes killer confounder region. can specified using killer_confounder flag, map chosen threshold value b*b^*.","code":"contour_plot(varW = var(weights),               sigma2 = var(poll.data$Y),              killer_confounder = 0.5,               df_benchmark = benchmark_results,              shade = TRUE,               label_size = 4)"},{"path":"https://melodyyhuang.github.io/senseweight/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Melody Huang. Author, maintainer.","code":""},{"path":"https://melodyyhuang.github.io/senseweight/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Huang M (2025). senseweight: Sensitivity Analysis Weighted Estimators. R package version 0.0.1, https://melodyyhuang.github.io/senseweight/.","code":"@Manual{,   title = {senseweight: Sensitivity Analysis for Weighted Estimators},   author = {Melody Huang},   year = {2025},   note = {R package version 0.0.1},   url = {https://melodyyhuang.github.io/senseweight/}, }"},{"path":"https://melodyyhuang.github.io/senseweight/index.html","id":"senseweight","dir":"","previous_headings":"","what":"Sensitivity Analysis for Weighted Estimators","title":"Sensitivity Analysis for Weighted Estimators","text":"senseweight implements set sensitivity functions tools help researchers transparently conduct sensitivity analyses weighted estimators. senseweight allows researchers assess sensitivity present weighted estimates omitted confounders. Specific methods provided senseweight include following: (1) visualization tools summarize sensitivity; (2) summary tables containing necessary sensitivity statistics; (3) formal benchmarking methods allow researchers use observed covariates assess plausibility different confounders.","code":""},{"path":"https://melodyyhuang.github.io/senseweight/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Sensitivity Analysis for Weighted Estimators","text":"can install development version senseweight GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"melodyyhuang/senseweight\")"},{"path":"https://melodyyhuang.github.io/senseweight/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Sensitivity Analysis for Weighted Estimators","text":"package implements series methods developed following papers. technical introduction sensitivity tools: Huang, Melody. “Sensitivity Analysis Generalization Experimental Results.” Journal Royal Statistical Society Series : Statistics Society (2024) Hartman, Erin Huang, Melody. “Sensitivity Analysis Survey Weights.” Political Analysis (2024) less technical introductions interesting applications best practice: Huang, Melody Hartman, Erin. “Assessing Nonignorable Response: Sensitivity Analysis Survey Weighting, Applications Survey Estimates COVID-19 Vaccination Uptake.” Working paper. Bailey, Michael. “Polling Crossroads.” (Chapter 7)","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/benchmark.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to benchmark an instance — benchmark","title":"Helper function to benchmark an instance — benchmark","text":"Returns benchmarking results single covariate (single group covariates)","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/benchmark.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to benchmark an instance — benchmark","text":"","code":"benchmark(   omit,   weights,   data,   sigma2,   estimand = \"ATT\",   weighting_method = \"ebal\",   weight_max = Inf )"},{"path":"https://melodyyhuang.github.io/senseweight/reference/benchmark.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to benchmark an instance — benchmark","text":"omit Variable omit weights Vector estimated weights data data.frame containing outcomes covariate information sigma2 Variance outcome variable estimand Specifies estimand; possible parameters include \"ATT\" \"PATE\", weighting_method Weighting method. Supports weighting methods package WeightIt. weight_max Maximum weight trim . Default set Inf","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/benchmark.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to benchmark an instance — benchmark","text":"Benchmarking results single covariate","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/benchmark_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function for benchmarking for sensitivity parameters — benchmark_parameters","title":"Helper function for benchmarking for sensitivity parameters — benchmark_parameters","text":"Helper function returns parameter estimates omitted variable specified relative confounding strength observed covariate (set covariates)","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/benchmark_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function for benchmarking for sensitivity parameters — benchmark_parameters","text":"","code":"benchmark_parameters(   weights,   weights_benchmark,   k_sigma = 1,   k_rho = 1,   Y,   Z,   sigma2,   estimand = \"ATT\" )"},{"path":"https://melodyyhuang.github.io/senseweight/reference/benchmark_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function for benchmarking for sensitivity parameters — benchmark_parameters","text":"weights Vector estimated weights weights_benchmark Vector estimated weights, omitting covariate (set covariates) used benchmark k_sigma Relative ability omitted confounder explain variation true weights. k_sigma > 1, expect omitted confounder explain variation true weights benchmarked covariate(s). k_sigma < 1, expect omitted confounder explain less variation true weights benchmarked covariate(s). Default set 1. k_rho Relative correlation omitted confounder outcome. k_rho > 1, expect omitted confounder correlated outcome benchmarked covariate(s). k_rho < 1, expect omitted confounder less correlated outcome benchmarked covariate(s). Default set 1. Y Vector outcomes Z Vector treatment assignment (necessary estimand = \"PATE\" order estimate covariances) sigma2 Estimated variance outcome (.e., stats::var(Y) obervational setting; stats::var(tau) generalization setting) estimand String specifying estimand interest. Valid inputs \"PATE\", \"Augmented\", \"ATT\", \"Survey\".","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/benchmark_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function for benchmarking for sensitivity parameters — benchmark_parameters","text":"data.frame containing estimated parameter values confounder specified relative confounder strength observed covariate (set covariates), well estimated bias omitted confounder.","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/benchmark_parameters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper function for benchmarking for sensitivity parameters — benchmark_parameters","text":"","code":"data(jtpa_women) site_name <- \"NE\" df_site <- jtpa_women[which(jtpa_women$site == site_name), ] df_else <- jtpa_women[which(jtpa_women$site != site_name), ]  # Estimate unweighted estimator: model_dim <- estimatr::lm_robust(Y ~ T, data = df_site) PATE <- coef(lm(Y ~ T, data = df_else))[2] DiM <- coef(model_dim)[2] # Generate weights using observed covariates: df_all <- jtpa_women df_all$S <- ifelse(jtpa_women$site == \"NE\", 1, 0) model_ps <- WeightIt::weightit(   (1 - S) ~ . - site - T - Y,    data = df_all, method = \"ebal\", estimand = \"ATT\" ) weights <- model_ps$weights[df_all$S == 1] # Estimate IPW model: model_ipw <- estimatr::lm_robust(Y ~ T, data = df_site, weights = weights) ipw <- coef(model_ipw)[2] # Estimate bound for var(tau): vartau <- var(df_site$Y[df_site$T == 1]) - var(df_site$Y[df_site$T == 0]) RV <- robustness_value(estimate = ipw, b_star = 0, sigma2 = vartau, weights = weights)  # Select weighting variables: weighting_vars <- names(df_all)[which(!names(df_all) %in% c(\"site\", \"S\", \"Y\", \"T\"))]  # Run benchmarking: df_benchmark <- run_benchmarking(   weighting_vars = weighting_vars,   data = df_all[, -1],   treatment = \"T\", outcome = \"Y\", selection = \"S\",   estimate = ipw,   RV = RV, sigma2 = vartau,   estimand = \"PATE\" )  print(df_benchmark) #>   variable R2_benchmark rho_benchmark    bias    MRCS k_sigma_min k_rho_min #> 1 prevearn         0.04         -0.22 -115.00  -11.80        9.99     -2.92 #> 2      age         0.06         -0.09  -55.45  -24.47        6.91     -7.37 #> 3  married         0.11          0.00   -2.52 -539.33        3.82   -224.19 #> 4   hrwage         0.05          0.02   13.51  100.40        8.32     27.40 #> 5    black         0.20         -0.03  -33.11  -40.97        2.03    -24.72 #> 6 hispanic         0.14         -0.06  -62.63  -21.66        3.01    -10.30 #> 7  hsorged         0.12          0.10   95.06   14.27        3.51      6.22 #> 8 yrs_educ         0.00         -0.07   -5.23 -259.49      408.90     -9.85"},{"path":"https://melodyyhuang.github.io/senseweight/reference/benchmark_survey.html","id":null,"dir":"Reference","previous_headings":"","what":"Benchmark (for survey weights) — benchmark_survey","title":"Benchmark (for survey weights) — benchmark_survey","text":"Returns benchmarking results survey weighting","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/benchmark_survey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Benchmark (for survey weights) — benchmark_survey","text":"","code":"benchmark_survey(   omit,   formula,   weights,   pop_svy = NULL,   sample_svy,   Y,   population_targets = NULL,   weighting_method = \"raking\" )"},{"path":"https://melodyyhuang.github.io/senseweight/reference/benchmark_survey.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Benchmark (for survey weights) — benchmark_survey","text":"omit Variable benchmark formula Raking formula weights vector, containing estimated survey weights pop_svy Survey object, containing population survey sample re-weighted sample_svy Survey object, containing survey sample re-weighted Y outcome interest population_targets Population targets raking formula (optional, provided, generated pop_svy) weighting_method Weighting method (default raking)","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/benchmark_survey.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Benchmark (for survey weights) — benchmark_survey","text":"Benchmarking results variable (subset variables)","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/benchmark_survey.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Benchmark (for survey weights) — benchmark_survey","text":"","code":"data(poll.data) poll_srs <- survey::svydesign(ids = ~ 1, data = poll.data) #> Warning: No weights or probabilities supplied, assuming equal probability pop_targets = c(1, 0.212, 0.264, 0.236, 0.310,                  0.114, 0.360, 0.528, 0.114,                  0.021, 0.034, 0.805,                  0.266, 0.075, 0.312, 0.349) names(pop_targets) = c(\"(Intercept)\",                        \"age_buckets36to50\",                        \"age_buckets51to64\",                        \"age_bucketsOver65\",                        \"educHigh School or Less\",                        \"educPost-grad\",                        \"educSome college\",                        \"genderWomen\",                         \"raceBlack\",                        \"raceHispanic\",                        \"raceOther\",                        \"raceWhite\",                         \"pidIndependent\", \"pidOther\",                         \"pidRepublican\", \"bornagainYes\") #Set up raking formula: formula_rake <- ~ age_buckets + educ + gender + race + pid + bornagain  #PERFORM RAKING: model_rake <- survey::calibrate(   design = poll_srs,   formula = formula_rake,   population = pop_targets,   calfun = \"raking\",   force = TRUE )   rake_results <- survey::svydesign( ~ 1, data = poll.data, weights = stats::weights(model_rake)) #Estimate from raking results: weights = stats::weights(rake_results) * nrow(model_rake)  unweighted_estimate = survey::svymean(~ Y, poll_srs, na.rm = TRUE) weighted_estimate = survey::svymean(~ Y, model_rake, na.rm = TRUE) benchmark_survey('educ',                   formula = formula_rake,                  weights = weights,                  population_targets = pop_targets,                  sample_svy = poll_srs,                  Y = poll.data$Y) #>   variable R2_benchmark rho_benchmark       bias #> 1     educ    0.3193473    0.06009261 0.02545009"},{"path":"https://melodyyhuang.github.io/senseweight/reference/contour_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Bias Contour Plots — contour_plot","title":"Bias Contour Plots — contour_plot","text":"Generates bias contour plots aid sensitivity analysis","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/contour_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bias Contour Plots — contour_plot","text":"","code":"contour_plot(   varW,   sigma2,   killer_confounder,   df_benchmark,   benchmark = TRUE,   shade = FALSE,   shade_var = NULL,   shade_fill = \"#35a4bf\",   shade_alpha = 0.25,   contour_width = 1,   binwidth = NULL,   label_size = 0.25,   point_size = 1,   nudge = 0.05,   axis_text_size = 12,   axis_title_size = 14,   axis_line_width = 1,   print = FALSE )"},{"path":"https://melodyyhuang.github.io/senseweight/reference/contour_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bias Contour Plots — contour_plot","text":"varW Variance estimated weights sigma2 Estimated variance outcome (.e., stats::var(Y) obervational setting; stats::var(tau) generalization setting)#' killer_confounder Threshold bias considered large enough killer confounder. example, researchers concerned bias large enough reduce estimated treatment effect zero change directional sign, set killer_confounder equal point estimate. df_benchmark Data frame containing formal benchmarking results. data.frame  must contain columns variable (covariate name), R2_benchmark, rho_benchmark. benchmark Flag whether display benchmarking results (benchmark = TRUE want add benchmarking results plot, benchamrk=FALSE otherwise). set TRUE, df_benchmark must contain valid benchmarking results. shade Flag whether specific benchmarking covariate (set benchmarked covariates) shaded different color (shade = TRUE indicates want highlight specific variables) shade_var shade = TRUE, contains either vector containing variables want highlight shade_fill Color fill highlighted variables. Default set \"#35a4bf\". shade_alpha Alpha value fill color. Default set 0.25. contour_width Width contour lines. Default set 1. binwidth set numeric value, function generate contour plot specified binwidth. Default set NULL. label_size Size labels. Default set 0.25. point_size Size points. Default set 1. nudge Nudge value labels. Default set 0.05. axis_text_size Size axis text. Default set 12. axis_title_size Size axis title. Default set 14. axis_line_width Width axis lines. Default set 1. print set TRUE, function return list two elements: plot contains generated bias contour plot, data, provides data.frame generating contour plot. set FALSE, function simply generate bias contour plot. Default set FALSE.","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/contour_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bias Contour Plots — contour_plot","text":"ggplot2 object, containing bias contour plot","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/contour_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bias Contour Plots — contour_plot","text":"","code":"# For the external validity setting:  data(jtpa_women) site_name <- \"NE\" df_site <- jtpa_women[which(jtpa_women$site == site_name), ] df_else <- jtpa_women[which(jtpa_women$site != site_name), ]  # Estimate unweighted estimator: model_dim <- estimatr::lm_robust(Y ~ T, data = df_site) PATE <- coef(lm(Y ~ T, data = df_else))[2] DiM <- coef(model_dim)[2] # Generate weights using observed covariates: df_all <- jtpa_women df_all$S <- ifelse(jtpa_women$site == \"NE\", 1, 0) model_ps <- WeightIt::weightit(   (1 - S) ~ . - site - T - Y,    data = df_all, method = \"ebal\", estimand = \"ATT\" ) weights <- model_ps$weights[df_all$S == 1] # Estimate IPW model: model_ipw <- estimatr::lm_robust(Y ~ T, data = df_site, weights = weights) ipw <- coef(model_ipw)[2] # Estimate bound for var(tau): vartau <- var(df_site$Y[df_site$T == 1]) - var(df_site$Y[df_site$T == 0]) RV <- robustness_value(estimate = ipw, b_star = 0, sigma2 = vartau, weights = weights)  # Select weighting variables: weighting_vars <- names(df_all)[which(!names(df_all) %in% c(\"site\", \"S\", \"Y\", \"T\"))]  # Run benchmarking: df_benchmark <- run_benchmarking(   weighting_vars = weighting_vars,   data = df_all[, -1],   treatment = \"T\", outcome = \"Y\", selection = \"S\",   estimate = ipw,   RV = RV, sigma2 = vartau,   estimand = \"PATE\" ) # Generate bias contour plot: contour_plot( var(weights), vartau, ipw, df_benchmark, benchmark = TRUE, shade = TRUE, shade_var = c(\"age\", \"prevearn\"), label_size = 4 )"},{"path":"https://melodyyhuang.github.io/senseweight/reference/create_targets.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function for creating targets from auxiliary information and formula — create_targets","title":"Helper function for creating targets from auxiliary information and formula — create_targets","text":"Returns weighting targets survey objects.","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/create_targets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function for creating targets from auxiliary information and formula — create_targets","text":"","code":"create_targets(target_design, target_formula)"},{"path":"https://melodyyhuang.github.io/senseweight/reference/create_targets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function for creating targets from auxiliary information and formula — create_targets","text":"target_design survey object target_formula formula object contains variables weight ","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/create_targets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function for creating targets from auxiliary information and formula — create_targets","text":"Weighting target survey objects","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/create_targets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper function for creating targets from auxiliary information and formula — create_targets","text":"","code":"data(poll.data) poll.svy = survey::svydesign(ids = ~ 1,                      data = poll.data) #> Warning: No weights or probabilities supplied, assuming equal probability  #Set up raking formula: formula_rake = ~ age_buckets + educ + gender + race + educ * pid + bornagain  #Generate targets: targets_rake = create_targets(poll.svy, formula_rake)"},{"path":"https://melodyyhuang.github.io/senseweight/reference/estimate_bias.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Bias — estimate_bias","title":"Estimate Bias — estimate_bias","text":"Returns bias based different parameters bias decomposition","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/estimate_bias.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Bias — estimate_bias","text":"","code":"estimate_bias(rho, R2, weights, sigma2)"},{"path":"https://melodyyhuang.github.io/senseweight/reference/estimate_bias.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Bias — estimate_bias","text":"rho Correlation error weights outcome R2 R2 measure much variation true weights explained error term, must bound range [0,1) weights Vector estimated weights sigma2 Estimated variance outcome (.e., stats::var(Y) obervational setting; stats::var(tau) generalization setting)","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/estimate_bias.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Bias — estimate_bias","text":"Estimated bias omitting confounder weights","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/estimate_bias.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Bias — estimate_bias","text":"","code":"set.seed(331) Y = rnorm(1000) weights = rlogis(1000) weights = weights/mean(weights) estimate_bias(rho = 0.5, R2 = 0.5, weights = weights, sigma2 = var(Y)) #> [1] 40.30893"},{"path":"https://melodyyhuang.github.io/senseweight/reference/jtpa_women.html","id":null,"dir":"Reference","previous_headings":"","what":"National Jobs Training Partnership Act (JTPA) Experimental Data — jtpa_women","title":"National Jobs Training Partnership Act (JTPA) Experimental Data — jtpa_women","text":"dataset containing earnings demographic characteristics individuals identified women JTPA experiment, spanning 16 different experimental sites.","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/jtpa_women.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"National Jobs Training Partnership Act (JTPA) Experimental Data — jtpa_women","text":"","code":"jtpa_women"},{"path":"https://melodyyhuang.github.io/senseweight/reference/jtpa_women.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"National Jobs Training Partnership Act (JTPA) Experimental Data — jtpa_women","text":"data frame 6109 total observations, 11 columns site Experimental site individual belonged Y Earnings, US dollars T Treatment assignment status prevearn Preivous earnings, US dollars age Age individual married Marital status (1 married, 0 otherwise) hrwage Hourly Wage black Indicator whether individual black hispanic Indicator whether individual Hispanic hsorged Indicator whether individual received high school degree, GED yrs_educ Number years education completed.","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/jtpa_women.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"National Jobs Training Partnership Act (JTPA) Experimental Data — jtpa_women","text":"https://www.upjohn.org/data-tools/employment-research-data-center/national-jtpa-study","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/poll.data.html","id":null,"dir":"Reference","previous_headings":"","what":"Synthetic Polling Data — poll.data","title":"Synthetic Polling Data — poll.data","text":"pid: party indicator, one c('Democrat', 'Republican', 'Independent', '') educ: education level, one c('High School Less', 'college', 'College', 'Post-grad') age: age individual age_buckets: grouped age buckets, one c('18to35', '36to50', '51to64', 'Over65') bornagain: indicator whether individual identifies born-Christian, one c('Yes', '') gender: categorical gender, one c('Men', 'Women') race: categorical race, one c('White', 'Black', 'Hispanic', 'Asian', '') vvweight_post: post-election verified voter weight individual","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/poll.data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Synthetic Polling Data — poll.data","text":"","code":"data('poll.data')"},{"path":"https://melodyyhuang.github.io/senseweight/reference/poll.data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Synthetic Polling Data — poll.data","text":"synthetically generated dataset simulates polling data hypothetical support. covariates constructed match commonly used demographic covariates practice.","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/poll.data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Synthetic Polling Data — poll.data","text":"\"Sensitivity analysis survey weights,\" Political Analysis, 32(1) (2024), 1-16. #'","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/poll.data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Synthetic Polling Data — poll.data","text":"","code":"data('poll.data')"},{"path":"https://melodyyhuang.github.io/senseweight/reference/robustness_value.html","id":null,"dir":"Reference","previous_headings":"","what":"Robustness Value — robustness_value","title":"Robustness Value — robustness_value","text":"Returns estimated robustness value, specified proportion change","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/robustness_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Robustness Value — robustness_value","text":"","code":"robustness_value(estimate, b_star = 0, sigma2, weights)"},{"path":"https://melodyyhuang.github.io/senseweight/reference/robustness_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Robustness Value — robustness_value","text":"estimate Weighted estimate b_star Threshold corresponds substantively meaningful change research conclusion. example, value 0 denotes bias omitting variable sufficiently large change estimate zero. sigma2 Estimated variance outcome (.e., stats::var(Y) obervational setting; stats::var(tau) generalization setting) weights Vector estimated weights","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/robustness_value.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Robustness Value — robustness_value","text":"Robustness value specified proportion change","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/robustness_value.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Robustness Value — robustness_value","text":"","code":"data(jtpa_women) site_name <- \"NE\" df_site <- jtpa_women[which(jtpa_women$site == site_name), ] df_else <- jtpa_women[which(jtpa_women$site != site_name), ]  # Estimate unweighted estimator: model_dim <- estimatr::lm_robust(Y ~ T, data = df_site) PATE <- coef(lm(Y ~ T, data = df_else))[2] DiM <- coef(model_dim)[2] # Generate weights using observed covariates: df_all <- jtpa_women df_all$S <- ifelse(jtpa_women$site == \"NE\", 1, 0) model_ps <- WeightIt::weightit(   (1 - S) ~ . - site - T - Y,    data = df_all, method = \"ebal\", estimand = \"ATT\" ) weights <- model_ps$weights[df_all$S == 1] # Estimate IPW model: model_ipw <- estimatr::lm_robust(Y ~ T, data = df_site, weights = weights) ipw <- coef(model_ipw)[2] # Estimate bound for var(tau): vartau <- var(df_site$Y[df_site$T == 1]) - var(df_site$Y[df_site$T == 0]) RV <- robustness_value(estimate = ipw, b_star = 0, sigma2 = vartau, weights = weights)  print(RV) #> [1] 0.4113622"},{"path":"https://melodyyhuang.github.io/senseweight/reference/run_benchmarking.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Formal Benchmarking — run_benchmarking","title":"Run Formal Benchmarking — run_benchmarking","text":"Wrapper function run formal benchmarking set pre-specified covariates. Returns data.frame containing benchmarked parameter values, estimated bias, MRCS, minimum k_sigma k_rho values killer confounder.","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/run_benchmarking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Formal Benchmarking — run_benchmarking","text":"","code":"run_benchmarking(   estimate,   RV,   formula = NULL,   weights = NULL,   pop_svy = NULL,   sample_svy = NULL,   Y = NULL,   weighting_vars = NULL,   benchmark_vars = \"all\",   data = NULL,   treatment = NULL,   outcome = NULL,   selection = NULL,   population_targets = NULL,   weighting_method = \"ebal\",   weight_max = Inf,   sigma2 = NULL,   estimand = \"ATT\" )"},{"path":"https://melodyyhuang.github.io/senseweight/reference/run_benchmarking.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Formal Benchmarking — run_benchmarking","text":"estimate Weighted estimate RV Robustness Value formula Raking formula survey estimand weights vector, containing estimated survey weights pop_svy Survey object, containing population survey sample re-weighted sample_svy Survey object, containing survey sample re-weighted Y outcome interest (used survey object) weighting_vars Vector variables use weights estimation ATT PATE benchmark_vars Vector variables benchmark parameters . benchmark_vars = '', benchmarking run across variables included weights. set , benchmarking conducted across covariates included vector. data data.frame containing observed covariates included weights; must include variables specified weighting_vars treatment Denotes variable treatment variable outcome Denotes variable outcome variable selection Denotes variable selection variable population_targets Population targets raking formula surveys (optional, provided, generated pop_svy) weighting_method Weighting method. Supports weighting methods package WeightIt. weight_max Maximum weight trim . Default set Inf. sigma2 estimand = \"PATE\", sigma2 must specify bound treatment effect heterogeneity. two estimands, function automatically calculate sample variance across control units, survey sample. estimand Specifies estimand; possible parameters include \"ATT\", \"PATE\", \"Survey\"","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/run_benchmarking.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Formal Benchmarking — run_benchmarking","text":"data.frame containing benchmarked parameter values, estimated bias, MRCS, minimum k_sigma k_rho values killer confounder set pre-specified covariates.","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/run_benchmarking.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run Formal Benchmarking — run_benchmarking","text":"","code":"# For the external validity setting:  data(jtpa_women) site_name <- \"NE\" df_site <- jtpa_women[which(jtpa_women$site == site_name), ] df_else <- jtpa_women[which(jtpa_women$site != site_name), ]  # Estimate unweighted estimator: model_dim <- estimatr::lm_robust(Y ~ T, data = df_site) PATE <- coef(lm(Y ~ T, data = df_else))[2] DiM <- coef(model_dim)[2] # Generate weights using observed covariates: df_all <- jtpa_women df_all$S <- ifelse(jtpa_women$site == \"NE\", 1, 0) model_ps <- WeightIt::weightit(   (1 - S) ~ . - site - T - Y,    data = df_all, method = \"ebal\", estimand = \"ATT\" ) weights <- model_ps$weights[df_all$S == 1] # Estimate IPW model: model_ipw <- estimatr::lm_robust(Y ~ T, data = df_site, weights = weights) ipw <- coef(model_ipw)[2] # Estimate bound for var(tau): vartau <- var(df_site$Y[df_site$T == 1]) - var(df_site$Y[df_site$T == 0]) RV <- robustness_value(estimate = ipw, b_star = 0, sigma2 = vartau, weights = weights)  # Select weighting variables: weighting_vars <- names(df_all)[which(!names(df_all) %in% c(\"site\", \"S\", \"Y\", \"T\"))]  # Run benchmarking: df_benchmark <- run_benchmarking(   weighting_vars = weighting_vars,   data = df_all[, -1],   treatment = \"T\", outcome = \"Y\", selection = \"S\",   estimate = ipw,   RV = RV, sigma2 = vartau,   estimand = \"PATE\" )  print(df_benchmark) #>   variable R2_benchmark rho_benchmark    bias    MRCS k_sigma_min k_rho_min #> 1 prevearn         0.04         -0.22 -115.00  -11.80        9.99     -2.92 #> 2      age         0.06         -0.09  -55.45  -24.47        6.91     -7.37 #> 3  married         0.11          0.00   -2.52 -539.33        3.82   -224.19 #> 4   hrwage         0.05          0.02   13.51  100.40        8.32     27.40 #> 5    black         0.20         -0.03  -33.11  -40.97        2.03    -24.72 #> 6 hispanic         0.14         -0.06  -62.63  -21.66        3.01    -10.30 #> 7  hsorged         0.12          0.10   95.06   14.27        3.51      6.22 #> 8 yrs_educ         0.00         -0.07   -5.23 -259.49      408.90     -9.85"},{"path":"https://melodyyhuang.github.io/senseweight/reference/senseweight-package.html","id":null,"dir":"Reference","previous_headings":"","what":"senseweight: Sensitivity Analysis for Weighted Estimators — senseweight-package","title":"senseweight: Sensitivity Analysis for Weighted Estimators — senseweight-package","text":"Provides tools conduct rigorous sensitivity analyses weighted estimators, introduced Huang (2024) doi:10.1093/jrsssa/qnae012  Hartman Huang (2024) doi:10.1017 . package allows researchers generate set recommended sensitivity summaries evaluate sensitivity underlying weighting estimators omitted moderators confounders. tools can flexibly applied causal inference settings (.e., external internal validity contexts) survey contexts.","code":""},{"path":[]},{"path":"https://melodyyhuang.github.io/senseweight/reference/senseweight-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"senseweight: Sensitivity Analysis for Weighted Estimators — senseweight-package","text":"Maintainer: Melody Huang melody.huang@yale.edu","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/summarize_sensitivity.html","id":null,"dir":"Reference","previous_headings":"","what":"Sensitivity Summary — summarize_sensitivity","title":"Sensitivity Summary — summarize_sensitivity","text":"Returns data.frame Kable table summary measures sensitivity","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/summarize_sensitivity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sensitivity Summary — summarize_sensitivity","text":"","code":"summarize_sensitivity(   weights = NULL,   Y = NULL,   Z = NULL,   b_star = 0,   estimate = NULL,   SE = NULL,   unweighted = NULL,   sigma2 = NULL,   estimand = \"ATT\",   pretty = FALSE,   svy_srs = NULL,   svy_wt = NULL,   sig.fig = 2 )"},{"path":"https://melodyyhuang.github.io/senseweight/reference/summarize_sensitivity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sensitivity Summary — summarize_sensitivity","text":"weights Vector estimated weights Y Outcome interest Z Treatment assignment (needed settings users analyzing surveys) b_star Killer confounder threshold. specified, automatically set 0. estimate (Optional) Weighted point estimate. specified, function automatically generate weighted estimator, given inputs Y weights SE (Optional) Standard error associated weighted point estimate unweighted (Optional) Unweighted point estimate. sigma2 (Optional) Variance outcomes individual-level treatment effect PATE case. case PATE estimator, specified, function automatically estimate upper bound variance individual-level treatment effect. estimand Specifies estimand; possible parameters include \"ATT\", \"PATE\", \"Survey\" pretty set TRUE, return Kable table. set FALSE, return data.frame. svy_srs Unweighted svymean object svy_wt Weighted svymean object sig.fig Significant figures round output (default set 2)","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/summarize_sensitivity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sensitivity Summary — summarize_sensitivity","text":"Sensitivity summary","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/summarize_sensitivity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sensitivity Summary — summarize_sensitivity","text":"","code":"data(jtpa_women) site_name <- \"NE\" df_site <- jtpa_women[which(jtpa_women$site == site_name), ] df_else <- jtpa_women[which(jtpa_women$site != site_name), ]  # Estimate unweighted estimator: model_dim <- estimatr::lm_robust(Y ~ T, data = df_site) PATE <- coef(lm(Y ~ T, data = df_else))[2] DiM <- coef(model_dim)[2] # Generate weights using observed covariates: df_all <- jtpa_women df_all$S <- ifelse(jtpa_women$site == \"NE\", 1, 0) model_ps <- WeightIt::weightit(   (1 - S) ~ . - site - T - Y,    data = df_all, method = \"ebal\", estimand = \"ATT\" ) weights <- model_ps$weights[df_all$S == 1] # Estimate IPW model: model_ipw <- estimatr::lm_robust(Y ~ T, data = df_site, weights = weights) ipw <- coef(model_ipw)[2] # Estimate bound for var(tau): vartau <- var(df_site$Y[df_site$T == 1]) - var(df_site$Y[df_site$T == 0]) summarize_sensitivity(weights = weights,  Y = df_site$Y,  Z = df_site$T,  sigma2 = vartau,  estimand = \"PATE\") #>   Unweighted Unweighted_SE Estimate     SE   RV sigma_tau_bound cor_w #> Z    1107.35        982.65  1356.66 1417.3 0.36          2897.9  0.07"},{"path":"https://melodyyhuang.github.io/senseweight/reference/summarize_sensitivity_survey.html","id":null,"dir":"Reference","previous_headings":"","what":"Sensitivity Summary (for survey weights) — summarize_sensitivity_survey","title":"Sensitivity Summary (for survey weights) — summarize_sensitivity_survey","text":"Returns data.frame Kable table summary measures sensitivity; helper function main summary function, allows users directly input survey object design object","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/summarize_sensitivity_survey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sensitivity Summary (for survey weights) — summarize_sensitivity_survey","text":"","code":"summarize_sensitivity_survey(svy_srs, svy_wt, weights, varY, b_star = 0)"},{"path":"https://melodyyhuang.github.io/senseweight/reference/summarize_sensitivity_survey.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sensitivity Summary (for survey weights) — summarize_sensitivity_survey","text":"svy_srs Survey object, containing unweighted survey svy_wt Survey object, containing weighted survey weights vector, containing estimated survey weights varY variance outcome b_star Killer confounder threshold, default set zero","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/summarize_sensitivity_survey.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sensitivity Summary (for survey weights) — summarize_sensitivity_survey","text":"Sensitivity data.frame latex table summary measures sensitivity","code":""},{"path":"https://melodyyhuang.github.io/senseweight/reference/summarize_sensitivity_survey.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sensitivity Summary (for survey weights) — summarize_sensitivity_survey","text":"","code":"data(poll.data) poll_srs <- survey::svydesign(ids = ~ 1, data = poll.data) #> Warning: No weights or probabilities supplied, assuming equal probability pop_targets = c(1, 0.212, 0.264, 0.236, 0.310,                  0.114, 0.360, 0.528, 0.114,                  0.021, 0.034, 0.805,                  0.266, 0.075, 0.312, 0.349) names(pop_targets) = c(\"(Intercept)\",                        \"age_buckets36to50\",                        \"age_buckets51to64\",                        \"age_bucketsOver65\",                        \"educHigh School or Less\",                        \"educPost-grad\",                        \"educSome college\",                        \"genderWomen\",                         \"raceBlack\",                        \"raceHispanic\",                        \"raceOther\",                        \"raceWhite\",                         \"pidIndependent\", \"pidOther\",                         \"pidRepublican\", \"bornagainYes\") #Set up raking formula: formula_rake <- ~ age_buckets + educ + gender + race + pid + bornagain  #PERFORM RAKING: model_rake <- survey::calibrate(   design = poll_srs,   formula = formula_rake,   population = pop_targets,   calfun = \"raking\",   force = TRUE )   rake_results <- survey::svydesign( ~ 1, data = poll.data, weights = stats::weights(model_rake)) #Estimate from raking results: weights = stats::weights(rake_results) * nrow(model_rake)  unweighted_estimate = survey::svymean(~ Y, poll_srs, na.rm = TRUE) weighted_estimate = survey::svymean(~ Y, model_rake, na.rm = TRUE) summarize_sensitivity(estimand = 'Survey', Y = poll.data$Y, weights = weights, svy_srs = unweighted_estimate,  svy_wt = weighted_estimate, b_star = 0.5) #>   Unweighted Unweighted_SE  Estimate        SE         RV #> 1       0.54     0.0157686 0.4684269 0.0167966 0.04977723"}]
